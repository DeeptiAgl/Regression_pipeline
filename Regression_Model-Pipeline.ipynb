{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.1-py3-none-win_amd64.whl (54.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\deepti\\anaconda3\\envs\\assignment\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\deepti\\anaconda3\\envs\\assignment\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.svm import SVR\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from mlxtend.Regressor import StackingCVRegressor #\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "# Used to ignore warnings generated from StackingCVClassifier\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_52721_99691_student-mat.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>other</td>\n",
       "      <td>reputation</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>reputation</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>services</td>\n",
       "      <td>teacher</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob     Fjob  \\\n",
       "172     GP   M   17       U     LE3       T     4     4   teacher    other   \n",
       "119     GP   M   15       U     GT3       T     3     4     other    other   \n",
       "389     MS   F   18       U     GT3       T     1     1     other    other   \n",
       "198     GP   F   17       U     GT3       T     4     4  services  teacher   \n",
       "139     GP   F   15       U     GT3       T     4     4   teacher  teacher   \n",
       "\n",
       "         reason guardian  traveltime  studytime  failures schoolsup famsup  \\\n",
       "172  reputation   mother           1          2         0        no    yes   \n",
       "119  reputation   father           1          1         0        no     no   \n",
       "389      course   mother           2          2         1        no     no   \n",
       "198        home   mother           2          1         1        no    yes   \n",
       "139      course   mother           2          1         0        no     no   \n",
       "\n",
       "    paid activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "172  yes        yes     yes    yes      yes       no       4         4      4   \n",
       "119   no         no     yes    yes      yes       no       3         4      3   \n",
       "389   no        yes     yes    yes       no       no       1         1      1   \n",
       "198   no         no     yes    yes      yes       no       4         2      4   \n",
       "139   no        yes     yes    yes      yes       no       4         3      2   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  \n",
       "172     1     3       5         0  13  11  \n",
       "119     1     2       4         6  14  13  \n",
       "389     1     1       5         0   6   5  \n",
       "198     2     3       2        24  18  18  \n",
       "139     1     1       5         0  16  16  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('G3', axis=1)\n",
    "y = df[['G3']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "num_transform = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "cat_transform = Pipeline(steps=[('oneHot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "       'nursery', 'higher', 'internet', 'romantic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.select_dtypes(include=['int64', 'float64']).drop(['G3'], axis=1).columns\n",
    "cat_features = df.select_dtypes(include=['object']).columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat',  OneHotEncoder(handle_unknown='ignore'), cat_features)])\n",
    "\n",
    "# preprocessor = make_column_transformer(\n",
    "#         (StandardScaler(), num_features),\n",
    "#         (OneHotEncoder(handle_unknown='ignore'), cat_features))\n",
    "\n",
    "# imputer_cat_pipeline = make_column_transformer(\n",
    "#     (make_pipeline(SimpleImputer(strategy='constant'), cat_columns_fill_miss),\n",
    "#     (make_pipeline(SimpleImputer(strategy='most_frequent'), cat_columns_fill_freq),\n",
    "# )\n",
    "\n",
    "# encoder_cat_pipeline = make_column_transformer(\n",
    "#     (OrdinalEncoder(categories=ord_mapping), cat_columns_ord),\n",
    "#     (OneHotEncoder(), cat_columns_onehot),\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 1000, n_jobs = -1)\n",
    "lr = LinearRegression(n_jobs = -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__randomforestregressor__n_estimators': [20, 73, 126, 180, 233, 286, 340, 393, 446, 500], 'model__randomforestregressor__max_features': ['auto', 'sqrt', 0.5], 'model__randomforestregressor__max_depth': [5, 15, 26, 36, 47, 57, 68, 78, 89, 99, 110, None], 'model__randomforestregressor__min_samples_split': [2, 5, 10], 'model__randomforestregressor__min_samples_leaf': [1, 3, 5, 7], 'model__randomforestregressor__bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 500, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt',0.5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 3, 5,7]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "params = {\n",
    "               'model__randomforestregressor__n_estimators': n_estimators,  #randomforestregressor__bootstrap\n",
    "               'model__randomforestregressor__max_features': max_features,\n",
    "               'model__randomforestregressor__max_depth': max_depth,\n",
    "               'model__randomforestregressor__min_samples_split': min_samples_split,\n",
    "               'model__randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
    "               'model__randomforestregressor__bootstrap': bootstrap,\n",
    "#               \"xgbclassifier__n_estimators\": [10, 50, 100, 500],\n",
    "#                 \"xgbclassifier__learning_rate\": [0.1, 0.5, 1],\n",
    "         }\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "                                   ('cat', OneHotEncoder(handle_unknown='ignore'),\n",
       "                                    Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))])),\n",
       "  ('model',\n",
       "   StackingCVRegressor(meta_regressor=LinearRegression(n_jobs=-1), random_state=42,\n",
       "                       regressors=Pipeline(steps=[('classifier',\n",
       "                                                   RandomForestRegressor(n_jobs=-1,\n",
       "                                                                         random_state=1000))]),\n",
       "                       use_features_in_secondary=True))],\n",
       " 'verbose': False,\n",
       " 'preprocessor': ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                  Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                 ('cat', OneHotEncoder(handle_unknown='ignore'),\n",
       "                                  Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "        'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "        'nursery', 'higher', 'internet', 'romantic'],\n",
       "       dtype='object'))]),\n",
       " 'model': StackingCVRegressor(meta_regressor=LinearRegression(n_jobs=-1), random_state=42,\n",
       "                     regressors=Pipeline(steps=[('classifier',\n",
       "                                                 RandomForestRegressor(n_jobs=-1,\n",
       "                                                                       random_state=1000))]),\n",
       "                     use_features_in_secondary=True),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'drop',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('num',\n",
       "   StandardScaler(),\n",
       "   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "  ('cat',\n",
       "   OneHotEncoder(handle_unknown='ignore'),\n",
       "   Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))],\n",
       " 'preprocessor__verbose': False,\n",
       " 'preprocessor__num': StandardScaler(),\n",
       " 'preprocessor__cat': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessor__num__copy': True,\n",
       " 'preprocessor__num__with_mean': True,\n",
       " 'preprocessor__num__with_std': True,\n",
       " 'preprocessor__cat__categories': 'auto',\n",
       " 'preprocessor__cat__drop': None,\n",
       " 'preprocessor__cat__dtype': numpy.float64,\n",
       " 'preprocessor__cat__handle_unknown': 'ignore',\n",
       " 'preprocessor__cat__sparse': True,\n",
       " 'model__cv': 5,\n",
       " 'model__meta_regressor__copy_X': True,\n",
       " 'model__meta_regressor__fit_intercept': True,\n",
       " 'model__meta_regressor__n_jobs': -1,\n",
       " 'model__meta_regressor__normalize': False,\n",
       " 'model__meta_regressor': LinearRegression(n_jobs=-1),\n",
       " 'model__n_jobs': None,\n",
       " 'model__pre_dispatch': '2*n_jobs',\n",
       " 'model__random_state': 42,\n",
       " 'model__refit': True,\n",
       " 'model__regressors__memory': None,\n",
       " 'model__regressors__steps': [('classifier',\n",
       "   RandomForestRegressor(n_jobs=-1, random_state=1000))],\n",
       " 'model__regressors__verbose': False,\n",
       " 'model__regressors__classifier': RandomForestRegressor(n_jobs=-1, random_state=1000),\n",
       " 'model__regressors__classifier__bootstrap': True,\n",
       " 'model__regressors__classifier__ccp_alpha': 0.0,\n",
       " 'model__regressors__classifier__criterion': 'mse',\n",
       " 'model__regressors__classifier__max_depth': None,\n",
       " 'model__regressors__classifier__max_features': 'auto',\n",
       " 'model__regressors__classifier__max_leaf_nodes': None,\n",
       " 'model__regressors__classifier__max_samples': None,\n",
       " 'model__regressors__classifier__min_impurity_decrease': 0.0,\n",
       " 'model__regressors__classifier__min_impurity_split': None,\n",
       " 'model__regressors__classifier__min_samples_leaf': 1,\n",
       " 'model__regressors__classifier__min_samples_split': 2,\n",
       " 'model__regressors__classifier__min_weight_fraction_leaf': 0.0,\n",
       " 'model__regressors__classifier__n_estimators': 100,\n",
       " 'model__regressors__classifier__n_jobs': -1,\n",
       " 'model__regressors__classifier__oob_score': False,\n",
       " 'model__regressors__classifier__random_state': 1000,\n",
       " 'model__regressors__classifier__verbose': 0,\n",
       " 'model__regressors__classifier__warm_start': False,\n",
       " 'model__regressors': Pipeline(steps=[('classifier',\n",
       "                  RandomForestRegressor(n_jobs=-1, random_state=1000))]),\n",
       " 'model__shuffle': True,\n",
       " 'model__store_train_meta_features': False,\n",
       " 'model__use_features_in_secondary': True,\n",
       " 'model__verbose': 0,\n",
       " 'model__randomforestregressor': RandomForestRegressor(n_jobs=-1, random_state=1000),\n",
       " 'model__randomforestregressor__bootstrap': True,\n",
       " 'model__randomforestregressor__ccp_alpha': 0.0,\n",
       " 'model__randomforestregressor__criterion': 'mse',\n",
       " 'model__randomforestregressor__max_depth': None,\n",
       " 'model__randomforestregressor__max_features': 'auto',\n",
       " 'model__randomforestregressor__max_leaf_nodes': None,\n",
       " 'model__randomforestregressor__max_samples': None,\n",
       " 'model__randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'model__randomforestregressor__min_impurity_split': None,\n",
       " 'model__randomforestregressor__min_samples_leaf': 1,\n",
       " 'model__randomforestregressor__min_samples_split': 2,\n",
       " 'model__randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'model__randomforestregressor__n_estimators': 100,\n",
       " 'model__randomforestregressor__n_jobs': -1,\n",
       " 'model__randomforestregressor__oob_score': False,\n",
       " 'model__randomforestregressor__random_state': 1000,\n",
       " 'model__randomforestregressor__verbose': 0,\n",
       " 'model__randomforestregressor__warm_start': False}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_stack.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(steps=[('classifier', rf)])\n",
    "\n",
    "# rf_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                       ('classifier', c3)])\n",
    "\n",
    "stacking_model = StackingCVRegressor(regressors=(rf_pipe), \n",
    "                            meta_regressor=lr,\n",
    "                            random_state=42,use_features_in_secondary=True)\n",
    "\n",
    "# pipe_stack = make_pipeline(preprocessor, stacking_model)\n",
    "pipe_stack = Pipeline([('preprocessor', preprocessor), ('model', stacking_model)])\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('preprocessor', preprocessor),('stack',stacking_model)\n",
    "# ])\n",
    "# params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "#           'randomforestclassifier__n_estimators': [10, 50],\n",
    "#           'meta_classifier__C': [0.1, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=pipe_stack, \n",
    "                    param_grid=params, \n",
    "                    cv=3,\n",
    "                    refit=True)\n",
    "grid.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
