{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.1-py3-none-win_amd64.whl (54.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\deepti\\anaconda3\\envs\\assignment\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\deepti\\anaconda3\\envs\\assignment\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier # \n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "# Used to ignore warnings generated from StackingCVClassifier\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_52721_99691_student-mat.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>other</td>\n",
       "      <td>reputation</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>reputation</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>services</td>\n",
       "      <td>teacher</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob     Fjob  \\\n",
       "172     GP   M   17       U     LE3       T     4     4   teacher    other   \n",
       "119     GP   M   15       U     GT3       T     3     4     other    other   \n",
       "389     MS   F   18       U     GT3       T     1     1     other    other   \n",
       "198     GP   F   17       U     GT3       T     4     4  services  teacher   \n",
       "139     GP   F   15       U     GT3       T     4     4   teacher  teacher   \n",
       "\n",
       "         reason guardian  traveltime  studytime  failures schoolsup famsup  \\\n",
       "172  reputation   mother           1          2         0        no    yes   \n",
       "119  reputation   father           1          1         0        no     no   \n",
       "389      course   mother           2          2         1        no     no   \n",
       "198        home   mother           2          1         1        no    yes   \n",
       "139      course   mother           2          1         0        no     no   \n",
       "\n",
       "    paid activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "172  yes        yes     yes    yes      yes       no       4         4      4   \n",
       "119   no         no     yes    yes      yes       no       3         4      3   \n",
       "389   no        yes     yes    yes       no       no       1         1      1   \n",
       "198   no         no     yes    yes      yes       no       4         2      4   \n",
       "139   no        yes     yes    yes      yes       no       4         3      2   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  \n",
       "172     1     3       5         0  13  11  \n",
       "119     1     2       4         6  14  13  \n",
       "389     1     1       5         0   6   5  \n",
       "198     2     3       2        24  18  18  \n",
       "139     1     1       5         0  16  16  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('G3', axis=1)\n",
    "y = df[['G3']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "num_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "cat_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('oneHot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.select_dtypes(include=['int64', 'float64']).drop(['G3'], axis=1).columns\n",
    "cat_features = df.select_dtypes(include=['object']).columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transform, num_features),\n",
    "        ('cat', cat_transform, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Support Vector classifier\n",
    "# c1 = SVC(C = 50, degree = 1, gamma = \"auto\", kernel = \"rbf\", probability = True)\n",
    "# c1 = SVC(random_state = 1000)\n",
    "\n",
    "# Initializing Multi-layer perceptron  classifier\n",
    "# c2 = MLPClassifier(activation = \"relu\", alpha = 0.1, hidden_layer_sizes = (10,10,10),\n",
    "#                             learning_rate = \"constant\", max_iter = 2000, random_state = 1000)\n",
    "\n",
    "# Initialing Nu Support Vector classifier\n",
    "# classifier3 = NuSVC(degree = 1, kernel = \"rbf\", nu = 0.25, probability = True)\n",
    "\n",
    "# Initializing Random Forest classifier\n",
    "# c3 = RandomForestClassifier(n_estimators = 500, criterion = \"gini\", max_depth = 10,\n",
    "#                                      max_features = \"auto\", min_samples_leaf = 0.005,\n",
    "#                                      min_samples_split = 0.005, n_jobs = -1, random_state = 1000)\n",
    "\n",
    "\n",
    "c2 = xgb.XGBClassifier( objective = 'multi:softmax')\n",
    "\n",
    "c3 = RandomForestClassifier(random_state = 1000, n_jobs = -1)\n",
    "meta_c = SVC(probability = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline-2__rf__n_estimators': [5, 10, 20], 'pipeline-2__rf__max_features': ['auto', 'sqrt', 0.5], 'pipeline-2__rf__max_depth': [5, 10, 15, 20, None], 'pipeline-2__rf__min_samples_split': [2, 5, 10], 'pipeline-2__rf__min_samples_leaf': [1, 3, 5, 7], 'pipeline-2__rf__bootstrap': [True, False], 'pipeline-1__xgb__n_estimators': [10, 50], 'pipeline-1__xgb__learning_rate': [0.5, 1]}\n"
     ]
    }
   ],
   "source": [
    "# n_estimators = [int(x) for x in np.linspace(start = 20, stop = 500, num = 10)]\n",
    "n_estimators = [5,10,20]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt',0.5]\n",
    "# Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(5, 110, num = 11)]\n",
    "max_depth = [5,10,15,20]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 3, 5,7]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "params = {'pipeline-2__rf__n_estimators': n_estimators,\n",
    "               'pipeline-2__rf__max_features': max_features,\n",
    "               'pipeline-2__rf__max_depth': max_depth,\n",
    "               'pipeline-2__rf__min_samples_split': min_samples_split,\n",
    "               'pipeline-2__rf__min_samples_leaf': min_samples_leaf,\n",
    "               'pipeline-2__rf__bootstrap': bootstrap,\n",
    "              \"pipeline-1__xgb__n_estimators\": [10, 50],\n",
    "                \"pipeline-1__xgb__learning_rate\": [0.5, 1],}\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-3f4bbf5ef4e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                     refit=True)\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mcv_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std_test_score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\mlxtend\\classifier\\stacking_cv_classification.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m                     \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m                     method='predict_proba' if self.use_probas else 'predict')\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_probas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    771\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[0;32m    772\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[1;32m--> 773\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[1;31m# Concatenate the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    822\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Assignment\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1370\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "# clf2 = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "# clf3 = GaussianNB()\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# pipe1 = make_pipeline(preprocessor,c2)\n",
    "# pipe2 = make_pipeline(preprocessor,c3)\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('preprocessor', preprocessor),('rf',rf)\n",
    "# ])\n",
    "\n",
    "\n",
    "xgb_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('xgb', c2)])\n",
    "\n",
    "rf_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('rf', c3)])\n",
    "\n",
    "stacking_model = StackingCVClassifier(classifiers=[xgb_pipe,rf_pipe], \n",
    "                            meta_classifier=meta_c,\n",
    "                            random_state=42)\n",
    "\n",
    "# params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "#           'randomforestclassifier__n_estimators': [10, 50],\n",
    "#           'meta_classifier__C': [0.1, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=stacking_model, \n",
    "                    param_grid=params, \n",
    "                    cv=3,\n",
    "                    refit=True)\n",
    "grid.fit(X, y)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifiers': [Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('num',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "         'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "        dtype='object')),\n",
       "                                                   ('cat',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     S...\n",
       "                                 interaction_constraints=None, learning_rate=None,\n",
       "                                 max_delta_step=None, max_depth=None,\n",
       "                                 min_child_weight=None, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=None, num_parallel_tree=None,\n",
       "                                 objective='multi:softmax', random_state=None,\n",
       "                                 reg_alpha=None, reg_lambda=None,\n",
       "                                 scale_pos_weight=None, subsample=None,\n",
       "                                 tree_method=None, validate_parameters=None,\n",
       "                                 verbosity=None))]),\n",
       "  Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('num',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "         'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "        dtype='object')),\n",
       "                                                   ('cat',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     S...puter(fill_value='missing',\n",
       "                                                                                   strategy='constant')),\n",
       "                                                                    ('oneHot',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "         'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "         'nursery', 'higher', 'internet', 'romantic'],\n",
       "        dtype='object'))])),\n",
       "                  ('rf', RandomForestClassifier(n_jobs=-1, random_state=1000))])],\n",
       " 'cv': 2,\n",
       " 'drop_last_proba': False,\n",
       " 'meta_classifier__C': 1.0,\n",
       " 'meta_classifier__break_ties': False,\n",
       " 'meta_classifier__cache_size': 200,\n",
       " 'meta_classifier__class_weight': None,\n",
       " 'meta_classifier__coef0': 0.0,\n",
       " 'meta_classifier__decision_function_shape': 'ovr',\n",
       " 'meta_classifier__degree': 3,\n",
       " 'meta_classifier__gamma': 'scale',\n",
       " 'meta_classifier__kernel': 'rbf',\n",
       " 'meta_classifier__max_iter': -1,\n",
       " 'meta_classifier__probability': True,\n",
       " 'meta_classifier__random_state': None,\n",
       " 'meta_classifier__shrinking': True,\n",
       " 'meta_classifier__tol': 0.001,\n",
       " 'meta_classifier__verbose': False,\n",
       " 'meta_classifier': SVC(probability=True),\n",
       " 'n_jobs': None,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'random_state': 42,\n",
       " 'shuffle': True,\n",
       " 'store_train_meta_features': False,\n",
       " 'stratify': True,\n",
       " 'use_clones': True,\n",
       " 'use_features_in_secondary': False,\n",
       " 'use_probas': False,\n",
       " 'verbose': 0,\n",
       " 'pipeline-1': Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                   ('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    S...\n",
       "                                interaction_constraints=None, learning_rate=None,\n",
       "                                max_delta_step=None, max_depth=None,\n",
       "                                min_child_weight=None, missing=nan,\n",
       "                                monotone_constraints=None, n_estimators=100,\n",
       "                                n_jobs=None, num_parallel_tree=None,\n",
       "                                objective='multi:softmax', random_state=None,\n",
       "                                reg_alpha=None, reg_lambda=None,\n",
       "                                scale_pos_weight=None, subsample=None,\n",
       "                                tree_method=None, validate_parameters=None,\n",
       "                                verbosity=None))]),\n",
       " 'pipeline-2': Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                   ('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    S...puter(fill_value='missing',\n",
       "                                                                                  strategy='constant')),\n",
       "                                                                   ('oneHot',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                   Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "        'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "        'nursery', 'higher', 'internet', 'romantic'],\n",
       "       dtype='object'))])),\n",
       "                 ('rf', RandomForestClassifier(n_jobs=-1, random_state=1000))]),\n",
       " 'pipeline-1__memory': None,\n",
       " 'pipeline-1__steps': [('preprocessor',\n",
       "   ColumnTransformer(transformers=[('num',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(strategy='median')),\n",
       "                                                    ('scaler', StandardScaler())]),\n",
       "                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                   strategy='constant')),\n",
       "                                                    ('oneHot',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                    Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))])),\n",
       "  ('xgb',\n",
       "   XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                 objective='multi:softmax', random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None))],\n",
       " 'pipeline-1__verbose': False,\n",
       " 'pipeline-1__preprocessor': ColumnTransformer(transformers=[('num',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(strategy='median')),\n",
       "                                                  ('scaler', StandardScaler())]),\n",
       "                                  Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                 strategy='constant')),\n",
       "                                                  ('oneHot',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                  Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "        'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "        'nursery', 'higher', 'internet', 'romantic'],\n",
       "       dtype='object'))]),\n",
       " 'pipeline-1__xgb': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               objective='multi:softmax', random_state=None, reg_alpha=None,\n",
       "               reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "               tree_method=None, validate_parameters=None, verbosity=None),\n",
       " 'pipeline-1__preprocessor__n_jobs': None,\n",
       " 'pipeline-1__preprocessor__remainder': 'drop',\n",
       " 'pipeline-1__preprocessor__sparse_threshold': 0.3,\n",
       " 'pipeline-1__preprocessor__transformer_weights': None,\n",
       " 'pipeline-1__preprocessor__transformers': [('num',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                   ('scaler', StandardScaler())]),\n",
       "   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "  ('cat',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                   ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       "   Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))],\n",
       " 'pipeline-1__preprocessor__verbose': False,\n",
       " 'pipeline-1__preprocessor__num': Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                 ('scaler', StandardScaler())]),\n",
       " 'pipeline-1__preprocessor__cat': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                 ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'pipeline-1__preprocessor__num__memory': None,\n",
       " 'pipeline-1__preprocessor__num__steps': [('imputer',\n",
       "   SimpleImputer(strategy='median')),\n",
       "  ('scaler', StandardScaler())],\n",
       " 'pipeline-1__preprocessor__num__verbose': False,\n",
       " 'pipeline-1__preprocessor__num__imputer': SimpleImputer(strategy='median'),\n",
       " 'pipeline-1__preprocessor__num__scaler': StandardScaler(),\n",
       " 'pipeline-1__preprocessor__num__imputer__add_indicator': False,\n",
       " 'pipeline-1__preprocessor__num__imputer__copy': True,\n",
       " 'pipeline-1__preprocessor__num__imputer__fill_value': None,\n",
       " 'pipeline-1__preprocessor__num__imputer__missing_values': nan,\n",
       " 'pipeline-1__preprocessor__num__imputer__strategy': 'median',\n",
       " 'pipeline-1__preprocessor__num__imputer__verbose': 0,\n",
       " 'pipeline-1__preprocessor__num__scaler__copy': True,\n",
       " 'pipeline-1__preprocessor__num__scaler__with_mean': True,\n",
       " 'pipeline-1__preprocessor__num__scaler__with_std': True,\n",
       " 'pipeline-1__preprocessor__cat__memory': None,\n",
       " 'pipeline-1__preprocessor__cat__steps': [('imputer',\n",
       "   SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "  ('oneHot', OneHotEncoder(handle_unknown='ignore'))],\n",
       " 'pipeline-1__preprocessor__cat__verbose': False,\n",
       " 'pipeline-1__preprocessor__cat__imputer': SimpleImputer(fill_value='missing', strategy='constant'),\n",
       " 'pipeline-1__preprocessor__cat__oneHot': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'pipeline-1__preprocessor__cat__imputer__add_indicator': False,\n",
       " 'pipeline-1__preprocessor__cat__imputer__copy': True,\n",
       " 'pipeline-1__preprocessor__cat__imputer__fill_value': 'missing',\n",
       " 'pipeline-1__preprocessor__cat__imputer__missing_values': nan,\n",
       " 'pipeline-1__preprocessor__cat__imputer__strategy': 'constant',\n",
       " 'pipeline-1__preprocessor__cat__imputer__verbose': 0,\n",
       " 'pipeline-1__preprocessor__cat__oneHot__categories': 'auto',\n",
       " 'pipeline-1__preprocessor__cat__oneHot__drop': None,\n",
       " 'pipeline-1__preprocessor__cat__oneHot__dtype': numpy.float64,\n",
       " 'pipeline-1__preprocessor__cat__oneHot__handle_unknown': 'ignore',\n",
       " 'pipeline-1__preprocessor__cat__oneHot__sparse': True,\n",
       " 'pipeline-1__xgb__objective': 'multi:softmax',\n",
       " 'pipeline-1__xgb__base_score': None,\n",
       " 'pipeline-1__xgb__booster': None,\n",
       " 'pipeline-1__xgb__colsample_bylevel': None,\n",
       " 'pipeline-1__xgb__colsample_bynode': None,\n",
       " 'pipeline-1__xgb__colsample_bytree': None,\n",
       " 'pipeline-1__xgb__gamma': None,\n",
       " 'pipeline-1__xgb__gpu_id': None,\n",
       " 'pipeline-1__xgb__importance_type': 'gain',\n",
       " 'pipeline-1__xgb__interaction_constraints': None,\n",
       " 'pipeline-1__xgb__learning_rate': None,\n",
       " 'pipeline-1__xgb__max_delta_step': None,\n",
       " 'pipeline-1__xgb__max_depth': None,\n",
       " 'pipeline-1__xgb__min_child_weight': None,\n",
       " 'pipeline-1__xgb__missing': nan,\n",
       " 'pipeline-1__xgb__monotone_constraints': None,\n",
       " 'pipeline-1__xgb__n_estimators': 100,\n",
       " 'pipeline-1__xgb__n_jobs': None,\n",
       " 'pipeline-1__xgb__num_parallel_tree': None,\n",
       " 'pipeline-1__xgb__random_state': None,\n",
       " 'pipeline-1__xgb__reg_alpha': None,\n",
       " 'pipeline-1__xgb__reg_lambda': None,\n",
       " 'pipeline-1__xgb__scale_pos_weight': None,\n",
       " 'pipeline-1__xgb__subsample': None,\n",
       " 'pipeline-1__xgb__tree_method': None,\n",
       " 'pipeline-1__xgb__validate_parameters': None,\n",
       " 'pipeline-1__xgb__verbosity': None,\n",
       " 'pipeline-2__memory': None,\n",
       " 'pipeline-2__steps': [('preprocessor',\n",
       "   ColumnTransformer(transformers=[('num',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(strategy='median')),\n",
       "                                                    ('scaler', StandardScaler())]),\n",
       "                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                   strategy='constant')),\n",
       "                                                    ('oneHot',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                    Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))])),\n",
       "  ('rf', RandomForestClassifier(n_jobs=-1, random_state=1000))],\n",
       " 'pipeline-2__verbose': False,\n",
       " 'pipeline-2__preprocessor': ColumnTransformer(transformers=[('num',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(strategy='median')),\n",
       "                                                  ('scaler', StandardScaler())]),\n",
       "                                  Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                 strategy='constant')),\n",
       "                                                  ('oneHot',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                  Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "        'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "        'nursery', 'higher', 'internet', 'romantic'],\n",
       "       dtype='object'))]),\n",
       " 'pipeline-2__rf': RandomForestClassifier(n_jobs=-1, random_state=1000),\n",
       " 'pipeline-2__preprocessor__n_jobs': None,\n",
       " 'pipeline-2__preprocessor__remainder': 'drop',\n",
       " 'pipeline-2__preprocessor__sparse_threshold': 0.3,\n",
       " 'pipeline-2__preprocessor__transformer_weights': None,\n",
       " 'pipeline-2__preprocessor__transformers': [('num',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                   ('scaler', StandardScaler())]),\n",
       "   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "  ('cat',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                   ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       "   Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))],\n",
       " 'pipeline-2__preprocessor__verbose': False,\n",
       " 'pipeline-2__preprocessor__num': Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                 ('scaler', StandardScaler())]),\n",
       " 'pipeline-2__preprocessor__cat': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                 ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'pipeline-2__preprocessor__num__memory': None,\n",
       " 'pipeline-2__preprocessor__num__steps': [('imputer',\n",
       "   SimpleImputer(strategy='median')),\n",
       "  ('scaler', StandardScaler())],\n",
       " 'pipeline-2__preprocessor__num__verbose': False,\n",
       " 'pipeline-2__preprocessor__num__imputer': SimpleImputer(strategy='median'),\n",
       " 'pipeline-2__preprocessor__num__scaler': StandardScaler(),\n",
       " 'pipeline-2__preprocessor__num__imputer__add_indicator': False,\n",
       " 'pipeline-2__preprocessor__num__imputer__copy': True,\n",
       " 'pipeline-2__preprocessor__num__imputer__fill_value': None,\n",
       " 'pipeline-2__preprocessor__num__imputer__missing_values': nan,\n",
       " 'pipeline-2__preprocessor__num__imputer__strategy': 'median',\n",
       " 'pipeline-2__preprocessor__num__imputer__verbose': 0,\n",
       " 'pipeline-2__preprocessor__num__scaler__copy': True,\n",
       " 'pipeline-2__preprocessor__num__scaler__with_mean': True,\n",
       " 'pipeline-2__preprocessor__num__scaler__with_std': True,\n",
       " 'pipeline-2__preprocessor__cat__memory': None,\n",
       " 'pipeline-2__preprocessor__cat__steps': [('imputer',\n",
       "   SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "  ('oneHot', OneHotEncoder(handle_unknown='ignore'))],\n",
       " 'pipeline-2__preprocessor__cat__verbose': False,\n",
       " 'pipeline-2__preprocessor__cat__imputer': SimpleImputer(fill_value='missing', strategy='constant'),\n",
       " 'pipeline-2__preprocessor__cat__oneHot': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'pipeline-2__preprocessor__cat__imputer__add_indicator': False,\n",
       " 'pipeline-2__preprocessor__cat__imputer__copy': True,\n",
       " 'pipeline-2__preprocessor__cat__imputer__fill_value': 'missing',\n",
       " 'pipeline-2__preprocessor__cat__imputer__missing_values': nan,\n",
       " 'pipeline-2__preprocessor__cat__imputer__strategy': 'constant',\n",
       " 'pipeline-2__preprocessor__cat__imputer__verbose': 0,\n",
       " 'pipeline-2__preprocessor__cat__oneHot__categories': 'auto',\n",
       " 'pipeline-2__preprocessor__cat__oneHot__drop': None,\n",
       " 'pipeline-2__preprocessor__cat__oneHot__dtype': numpy.float64,\n",
       " 'pipeline-2__preprocessor__cat__oneHot__handle_unknown': 'ignore',\n",
       " 'pipeline-2__preprocessor__cat__oneHot__sparse': True,\n",
       " 'pipeline-2__rf__bootstrap': True,\n",
       " 'pipeline-2__rf__ccp_alpha': 0.0,\n",
       " 'pipeline-2__rf__class_weight': None,\n",
       " 'pipeline-2__rf__criterion': 'gini',\n",
       " 'pipeline-2__rf__max_depth': None,\n",
       " 'pipeline-2__rf__max_features': 'auto',\n",
       " 'pipeline-2__rf__max_leaf_nodes': None,\n",
       " 'pipeline-2__rf__max_samples': None,\n",
       " 'pipeline-2__rf__min_impurity_decrease': 0.0,\n",
       " 'pipeline-2__rf__min_impurity_split': None,\n",
       " 'pipeline-2__rf__min_samples_leaf': 1,\n",
       " 'pipeline-2__rf__min_samples_split': 2,\n",
       " 'pipeline-2__rf__min_weight_fraction_leaf': 0.0,\n",
       " 'pipeline-2__rf__n_estimators': 100,\n",
       " 'pipeline-2__rf__n_jobs': -1,\n",
       " 'pipeline-2__rf__oob_score': False,\n",
       " 'pipeline-2__rf__random_state': 1000,\n",
       " 'pipeline-2__rf__verbose': 0,\n",
       " 'pipeline-2__rf__warm_start': False}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'select_dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-5479978f9419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_column_transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mnum_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float64'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mcat_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'select_dtypes'"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n_estimators = [20,50,100,250,500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt',0.5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 3, 5,7]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# rf = RandomForestRegressor(random_state = 1000, n_jobs = -1)\n",
    "\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "# X, y = load_boston(return_X_y=True)\n",
    "\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "rf = RandomForestRegressor()\n",
    "lr = LinearRegression(n_jobs = -1)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = y.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(), num_features),(OneHotEncoder(handle_unknown='ignore'),cat_features),remainder=\"passthrough\")\n",
    "\n",
    "\n",
    "stack = StackingCVRegressor(regressors=(rf, ridge),\n",
    "                            meta_regressor=lr, \n",
    "                            use_features_in_secondary=True)\n",
    "\n",
    "pipeline = make_pipeline(preprocess, stack)\n",
    "\n",
    "params = {\n",
    "#     'stackingcvregressor__lasso__alpha': [0.1, 1.0, 10.0],\n",
    "          'stackingcvregressor__ridge__alpha': [0.1, 1.0, 10.0],\n",
    "    'stackingcvregressor__randomforestregressor__n_estimators': n_estimators,\n",
    "         }\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    verbose=1,\n",
    "    estimator=pipeline, \n",
    "    param_grid=params, \n",
    "    cv=5,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('stackingcvregressor',\n",
       "   StackingCVRegressor(meta_regressor=LinearRegression(n_jobs=-1),\n",
       "                       regressors=(RandomForestRegressor(), Ridge()),\n",
       "                       use_features_in_secondary=True))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'stackingcvregressor': StackingCVRegressor(meta_regressor=LinearRegression(n_jobs=-1),\n",
       "                     regressors=(RandomForestRegressor(), Ridge()),\n",
       "                     use_features_in_secondary=True),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'stackingcvregressor__cv': 5,\n",
       " 'stackingcvregressor__meta_regressor__copy_X': True,\n",
       " 'stackingcvregressor__meta_regressor__fit_intercept': True,\n",
       " 'stackingcvregressor__meta_regressor__n_jobs': -1,\n",
       " 'stackingcvregressor__meta_regressor__normalize': False,\n",
       " 'stackingcvregressor__meta_regressor': LinearRegression(n_jobs=-1),\n",
       " 'stackingcvregressor__n_jobs': None,\n",
       " 'stackingcvregressor__pre_dispatch': '2*n_jobs',\n",
       " 'stackingcvregressor__random_state': None,\n",
       " 'stackingcvregressor__refit': True,\n",
       " 'stackingcvregressor__regressors': (RandomForestRegressor(), Ridge()),\n",
       " 'stackingcvregressor__shuffle': True,\n",
       " 'stackingcvregressor__store_train_meta_features': False,\n",
       " 'stackingcvregressor__use_features_in_secondary': True,\n",
       " 'stackingcvregressor__verbose': 0,\n",
       " 'stackingcvregressor__randomforestregressor': RandomForestRegressor(),\n",
       " 'stackingcvregressor__ridge': Ridge(),\n",
       " 'stackingcvregressor__randomforestregressor__bootstrap': True,\n",
       " 'stackingcvregressor__randomforestregressor__ccp_alpha': 0.0,\n",
       " 'stackingcvregressor__randomforestregressor__criterion': 'mse',\n",
       " 'stackingcvregressor__randomforestregressor__max_depth': None,\n",
       " 'stackingcvregressor__randomforestregressor__max_features': 'auto',\n",
       " 'stackingcvregressor__randomforestregressor__max_leaf_nodes': None,\n",
       " 'stackingcvregressor__randomforestregressor__max_samples': None,\n",
       " 'stackingcvregressor__randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'stackingcvregressor__randomforestregressor__min_impurity_split': None,\n",
       " 'stackingcvregressor__randomforestregressor__min_samples_leaf': 1,\n",
       " 'stackingcvregressor__randomforestregressor__min_samples_split': 2,\n",
       " 'stackingcvregressor__randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'stackingcvregressor__randomforestregressor__n_estimators': 100,\n",
       " 'stackingcvregressor__randomforestregressor__n_jobs': None,\n",
       " 'stackingcvregressor__randomforestregressor__oob_score': False,\n",
       " 'stackingcvregressor__randomforestregressor__random_state': None,\n",
       " 'stackingcvregressor__randomforestregressor__verbose': 0,\n",
       " 'stackingcvregressor__randomforestregressor__warm_start': False,\n",
       " 'stackingcvregressor__ridge__alpha': 1.0,\n",
       " 'stackingcvregressor__ridge__copy_X': True,\n",
       " 'stackingcvregressor__ridge__fit_intercept': True,\n",
       " 'stackingcvregressor__ridge__max_iter': None,\n",
       " 'stackingcvregressor__ridge__normalize': False,\n",
       " 'stackingcvregressor__ridge__random_state': None,\n",
       " 'stackingcvregressor__ridge__solver': 'auto',\n",
       " 'stackingcvregressor__ridge__tol': 0.001}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
