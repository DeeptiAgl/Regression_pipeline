{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.1-py3-none-win_amd64.whl (54.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\deepti\\anaconda3\\envs\\assignment\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\deepti\\anaconda3\\envs\\assignment\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier # \n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "# Used to ignore warnings generated from StackingCVClassifier\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_52721_99691_student-mat.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>schoolsup</th>\n",
       "      <th>famsup</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>other</td>\n",
       "      <td>reputation</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>reputation</td>\n",
       "      <td>father</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>services</td>\n",
       "      <td>teacher</td>\n",
       "      <td>home</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>teacher</td>\n",
       "      <td>course</td>\n",
       "      <td>mother</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob     Fjob  \\\n",
       "172     GP   M   17       U     LE3       T     4     4   teacher    other   \n",
       "119     GP   M   15       U     GT3       T     3     4     other    other   \n",
       "389     MS   F   18       U     GT3       T     1     1     other    other   \n",
       "198     GP   F   17       U     GT3       T     4     4  services  teacher   \n",
       "139     GP   F   15       U     GT3       T     4     4   teacher  teacher   \n",
       "\n",
       "         reason guardian  traveltime  studytime  failures schoolsup famsup  \\\n",
       "172  reputation   mother           1          2         0        no    yes   \n",
       "119  reputation   father           1          1         0        no     no   \n",
       "389      course   mother           2          2         1        no     no   \n",
       "198        home   mother           2          1         1        no    yes   \n",
       "139      course   mother           2          1         0        no     no   \n",
       "\n",
       "    paid activities nursery higher internet romantic  famrel  freetime  goout  \\\n",
       "172  yes        yes     yes    yes      yes       no       4         4      4   \n",
       "119   no         no     yes    yes      yes       no       3         4      3   \n",
       "389   no        yes     yes    yes       no       no       1         1      1   \n",
       "198   no         no     yes    yes      yes       no       4         2      4   \n",
       "139   no        yes     yes    yes      yes       no       4         3      2   \n",
       "\n",
       "     Dalc  Walc  health  absences  G1  G2  \n",
       "172     1     3       5         0  13  11  \n",
       "119     1     2       4         6  14  13  \n",
       "389     1     1       5         0   6   5  \n",
       "198     2     3       2        24  18  18  \n",
       "139     1     1       5         0  16  16  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('G3', axis=1)\n",
    "y = df[['G3']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "num_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "cat_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('oneHot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = df.select_dtypes(include=['int64', 'float64']).drop(['G3'], axis=1).columns\n",
    "cat_features = df.select_dtypes(include=['object']).columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transform, num_features),\n",
    "        ('cat', cat_transform, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Support Vector classifier\n",
    "# c1 = SVC(C = 50, degree = 1, gamma = \"auto\", kernel = \"rbf\", probability = True)\n",
    "# c1 = SVC(random_state = 1000)\n",
    "\n",
    "# Initializing Multi-layer perceptron  classifier\n",
    "# c2 = MLPClassifier(activation = \"relu\", alpha = 0.1, hidden_layer_sizes = (10,10,10),\n",
    "#                             learning_rate = \"constant\", max_iter = 2000, random_state = 1000)\n",
    "\n",
    "# Initialing Nu Support Vector classifier\n",
    "# classifier3 = NuSVC(degree = 1, kernel = \"rbf\", nu = 0.25, probability = True)\n",
    "\n",
    "# Initializing Random Forest classifier\n",
    "# c3 = RandomForestClassifier(n_estimators = 500, criterion = \"gini\", max_depth = 10,\n",
    "#                                      max_features = \"auto\", min_samples_leaf = 0.005,\n",
    "#                                      min_samples_split = 0.005, n_jobs = -1, random_state = 1000)\n",
    "\n",
    "\n",
    "c2 = xgb.XGBClassifier( objective = 'multi:softmax')\n",
    "\n",
    "c3 = RandomForestClassifier(random_state = 1000, n_jobs = -1)\n",
    "meta_c = SVC(probability = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline-2__classifier__n_estimators': [20, 73, 126, 180, 233, 286, 340, 393, 446, 500], 'pipeline-2__classifier__max_features': ['auto', 'sqrt', 0.5], 'pipeline-2__classifier__max_depth': [5, 15, 26, 36, 47, 57, 68, 78, 89, 99, 110, None], 'pipeline-2__classifier__min_samples_split': [2, 5, 10], 'pipeline-2__classifier__min_samples_leaf': [1, 3, 5, 7], 'pipeline-2__classifier__bootstrap': [True, False], 'pipeline-1__classifier__n_estimators': [10, 50, 100, 500], 'pipeline-1__classifier__learning_rate': [0.1, 0.5, 1]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 500, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt',0.5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 3, 5,7]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "params = {'pipeline-2__classifier__n_estimators': n_estimators,\n",
    "               'pipeline-2__classifier__max_features': max_features,\n",
    "               'pipeline-2__classifier__max_depth': max_depth,\n",
    "               'pipeline-2__classifier__min_samples_split': min_samples_split,\n",
    "               'pipeline-2__classifier__min_samples_leaf': min_samples_leaf,\n",
    "               'pipeline-2__classifier__bootstrap': bootstrap,\n",
    "              \"pipeline-1__classifier__n_estimators\": [10, 50, 100, 500],\n",
    "                \"pipeline-1__classifier__learning_rate\": [0.1, 0.5, 1],}\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "# clf2 = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "# clf3 = GaussianNB()\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# pipe1 = make_pipeline(preprocessor,c2)\n",
    "# pipe2 = make_pipeline(preprocessor,c3)\n",
    "\n",
    "xgb_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', c2)])\n",
    "\n",
    "rf_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', c3)])\n",
    "\n",
    "stacking_model = StackingCVClassifier(classifiers=[xgb_pipe,rf_pipe], \n",
    "                            meta_classifier=meta_c,\n",
    "                            random_state=42)\n",
    "\n",
    "# params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "#           'randomforestclassifier__n_estimators': [10, 50],\n",
    "#           'meta_classifier__C': [0.1, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=stacking_model, \n",
    "                    param_grid=params, \n",
    "                    cv=3,\n",
    "                    refit=True)\n",
    "grid.fit(X, y)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifiers': [Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('num',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "         'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "        dtype='object')),\n",
       "                                                   ('cat',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     S...\n",
       "                                 interaction_constraints=None, learning_rate=None,\n",
       "                                 max_delta_step=None, max_depth=None,\n",
       "                                 min_child_weight=None, missing=nan,\n",
       "                                 monotone_constraints=None, n_estimators=100,\n",
       "                                 n_jobs=None, num_parallel_tree=None,\n",
       "                                 objective='multi:softmax', random_state=None,\n",
       "                                 reg_alpha=None, reg_lambda=None,\n",
       "                                 scale_pos_weight=None, subsample=None,\n",
       "                                 tree_method=None, validate_parameters=None,\n",
       "                                 verbosity=None))]),\n",
       "  Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('num',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     SimpleImputer(strategy='median')),\n",
       "                                                                    ('scaler',\n",
       "                                                                     StandardScaler())]),\n",
       "                                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "         'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "        dtype='object')),\n",
       "                                                   ('cat',\n",
       "                                                    Pipeline(steps=[('imputer',\n",
       "                                                                     S...ll_value='missing',\n",
       "                                                                                   strategy='constant')),\n",
       "                                                                    ('oneHot',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                    Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "         'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "         'nursery', 'higher', 'internet', 'romantic'],\n",
       "        dtype='object'))])),\n",
       "                  ('classifier',\n",
       "                   RandomForestClassifier(n_jobs=-1, random_state=1000))])],\n",
       " 'cv': 2,\n",
       " 'drop_last_proba': False,\n",
       " 'meta_classifier__C': 1.0,\n",
       " 'meta_classifier__break_ties': False,\n",
       " 'meta_classifier__cache_size': 200,\n",
       " 'meta_classifier__class_weight': None,\n",
       " 'meta_classifier__coef0': 0.0,\n",
       " 'meta_classifier__decision_function_shape': 'ovr',\n",
       " 'meta_classifier__degree': 3,\n",
       " 'meta_classifier__gamma': 'scale',\n",
       " 'meta_classifier__kernel': 'rbf',\n",
       " 'meta_classifier__max_iter': -1,\n",
       " 'meta_classifier__probability': True,\n",
       " 'meta_classifier__random_state': None,\n",
       " 'meta_classifier__shrinking': True,\n",
       " 'meta_classifier__tol': 0.001,\n",
       " 'meta_classifier__verbose': False,\n",
       " 'meta_classifier': SVC(probability=True),\n",
       " 'n_jobs': None,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'random_state': 42,\n",
       " 'shuffle': True,\n",
       " 'store_train_meta_features': False,\n",
       " 'stratify': True,\n",
       " 'use_clones': True,\n",
       " 'use_features_in_secondary': False,\n",
       " 'use_probas': False,\n",
       " 'verbose': 0,\n",
       " 'pipeline-1': Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                   ('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    S...\n",
       "                                interaction_constraints=None, learning_rate=None,\n",
       "                                max_delta_step=None, max_depth=None,\n",
       "                                min_child_weight=None, missing=nan,\n",
       "                                monotone_constraints=None, n_estimators=100,\n",
       "                                n_jobs=None, num_parallel_tree=None,\n",
       "                                objective='multi:softmax', random_state=None,\n",
       "                                reg_alpha=None, reg_lambda=None,\n",
       "                                scale_pos_weight=None, subsample=None,\n",
       "                                tree_method=None, validate_parameters=None,\n",
       "                                verbosity=None))]),\n",
       " 'pipeline-2': Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(transformers=[('num',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    SimpleImputer(strategy='median')),\n",
       "                                                                   ('scaler',\n",
       "                                                                    StandardScaler())]),\n",
       "                                                   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    S...ll_value='missing',\n",
       "                                                                                  strategy='constant')),\n",
       "                                                                   ('oneHot',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                   Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "        'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "        'nursery', 'higher', 'internet', 'romantic'],\n",
       "       dtype='object'))])),\n",
       "                 ('classifier',\n",
       "                  RandomForestClassifier(n_jobs=-1, random_state=1000))]),\n",
       " 'pipeline-1__memory': None,\n",
       " 'pipeline-1__steps': [('preprocessor',\n",
       "   ColumnTransformer(transformers=[('num',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(strategy='median')),\n",
       "                                                    ('scaler', StandardScaler())]),\n",
       "                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                   strategy='constant')),\n",
       "                                                    ('oneHot',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                    Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))])),\n",
       "  ('classifier',\n",
       "   XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                 colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                 gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                 learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                 min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                 n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                 objective='multi:softmax', random_state=None, reg_alpha=None,\n",
       "                 reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                 tree_method=None, validate_parameters=None, verbosity=None))],\n",
       " 'pipeline-1__verbose': False,\n",
       " 'pipeline-1__preprocessor': ColumnTransformer(transformers=[('num',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(strategy='median')),\n",
       "                                                  ('scaler', StandardScaler())]),\n",
       "                                  Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                 strategy='constant')),\n",
       "                                                  ('oneHot',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                  Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "        'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "        'nursery', 'higher', 'internet', 'romantic'],\n",
       "       dtype='object'))]),\n",
       " 'pipeline-1__classifier': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               objective='multi:softmax', random_state=None, reg_alpha=None,\n",
       "               reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "               tree_method=None, validate_parameters=None, verbosity=None),\n",
       " 'pipeline-1__preprocessor__n_jobs': None,\n",
       " 'pipeline-1__preprocessor__remainder': 'drop',\n",
       " 'pipeline-1__preprocessor__sparse_threshold': 0.3,\n",
       " 'pipeline-1__preprocessor__transformer_weights': None,\n",
       " 'pipeline-1__preprocessor__transformers': [('num',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                   ('scaler', StandardScaler())]),\n",
       "   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "  ('cat',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                   ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       "   Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))],\n",
       " 'pipeline-1__preprocessor__verbose': False,\n",
       " 'pipeline-1__preprocessor__num': Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                 ('scaler', StandardScaler())]),\n",
       " 'pipeline-1__preprocessor__cat': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                 ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'pipeline-1__preprocessor__num__memory': None,\n",
       " 'pipeline-1__preprocessor__num__steps': [('imputer',\n",
       "   SimpleImputer(strategy='median')),\n",
       "  ('scaler', StandardScaler())],\n",
       " 'pipeline-1__preprocessor__num__verbose': False,\n",
       " 'pipeline-1__preprocessor__num__imputer': SimpleImputer(strategy='median'),\n",
       " 'pipeline-1__preprocessor__num__scaler': StandardScaler(),\n",
       " 'pipeline-1__preprocessor__num__imputer__add_indicator': False,\n",
       " 'pipeline-1__preprocessor__num__imputer__copy': True,\n",
       " 'pipeline-1__preprocessor__num__imputer__fill_value': None,\n",
       " 'pipeline-1__preprocessor__num__imputer__missing_values': nan,\n",
       " 'pipeline-1__preprocessor__num__imputer__strategy': 'median',\n",
       " 'pipeline-1__preprocessor__num__imputer__verbose': 0,\n",
       " 'pipeline-1__preprocessor__num__scaler__copy': True,\n",
       " 'pipeline-1__preprocessor__num__scaler__with_mean': True,\n",
       " 'pipeline-1__preprocessor__num__scaler__with_std': True,\n",
       " 'pipeline-1__preprocessor__cat__memory': None,\n",
       " 'pipeline-1__preprocessor__cat__steps': [('imputer',\n",
       "   SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "  ('oneHot', OneHotEncoder(handle_unknown='ignore'))],\n",
       " 'pipeline-1__preprocessor__cat__verbose': False,\n",
       " 'pipeline-1__preprocessor__cat__imputer': SimpleImputer(fill_value='missing', strategy='constant'),\n",
       " 'pipeline-1__preprocessor__cat__oneHot': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'pipeline-1__preprocessor__cat__imputer__add_indicator': False,\n",
       " 'pipeline-1__preprocessor__cat__imputer__copy': True,\n",
       " 'pipeline-1__preprocessor__cat__imputer__fill_value': 'missing',\n",
       " 'pipeline-1__preprocessor__cat__imputer__missing_values': nan,\n",
       " 'pipeline-1__preprocessor__cat__imputer__strategy': 'constant',\n",
       " 'pipeline-1__preprocessor__cat__imputer__verbose': 0,\n",
       " 'pipeline-1__preprocessor__cat__oneHot__categories': 'auto',\n",
       " 'pipeline-1__preprocessor__cat__oneHot__drop': None,\n",
       " 'pipeline-1__preprocessor__cat__oneHot__dtype': numpy.float64,\n",
       " 'pipeline-1__preprocessor__cat__oneHot__handle_unknown': 'ignore',\n",
       " 'pipeline-1__preprocessor__cat__oneHot__sparse': True,\n",
       " 'pipeline-1__classifier__objective': 'multi:softmax',\n",
       " 'pipeline-1__classifier__base_score': None,\n",
       " 'pipeline-1__classifier__booster': None,\n",
       " 'pipeline-1__classifier__colsample_bylevel': None,\n",
       " 'pipeline-1__classifier__colsample_bynode': None,\n",
       " 'pipeline-1__classifier__colsample_bytree': None,\n",
       " 'pipeline-1__classifier__gamma': None,\n",
       " 'pipeline-1__classifier__gpu_id': None,\n",
       " 'pipeline-1__classifier__importance_type': 'gain',\n",
       " 'pipeline-1__classifier__interaction_constraints': None,\n",
       " 'pipeline-1__classifier__learning_rate': None,\n",
       " 'pipeline-1__classifier__max_delta_step': None,\n",
       " 'pipeline-1__classifier__max_depth': None,\n",
       " 'pipeline-1__classifier__min_child_weight': None,\n",
       " 'pipeline-1__classifier__missing': nan,\n",
       " 'pipeline-1__classifier__monotone_constraints': None,\n",
       " 'pipeline-1__classifier__n_estimators': 100,\n",
       " 'pipeline-1__classifier__n_jobs': None,\n",
       " 'pipeline-1__classifier__num_parallel_tree': None,\n",
       " 'pipeline-1__classifier__random_state': None,\n",
       " 'pipeline-1__classifier__reg_alpha': None,\n",
       " 'pipeline-1__classifier__reg_lambda': None,\n",
       " 'pipeline-1__classifier__scale_pos_weight': None,\n",
       " 'pipeline-1__classifier__subsample': None,\n",
       " 'pipeline-1__classifier__tree_method': None,\n",
       " 'pipeline-1__classifier__validate_parameters': None,\n",
       " 'pipeline-1__classifier__verbosity': None,\n",
       " 'pipeline-2__memory': None,\n",
       " 'pipeline-2__steps': [('preprocessor',\n",
       "   ColumnTransformer(transformers=[('num',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(strategy='median')),\n",
       "                                                    ('scaler', StandardScaler())]),\n",
       "                                    Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(steps=[('imputer',\n",
       "                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                   strategy='constant')),\n",
       "                                                    ('oneHot',\n",
       "                                                     OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                    Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))])),\n",
       "  ('classifier', RandomForestClassifier(n_jobs=-1, random_state=1000))],\n",
       " 'pipeline-2__verbose': False,\n",
       " 'pipeline-2__preprocessor': ColumnTransformer(transformers=[('num',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(strategy='median')),\n",
       "                                                  ('scaler', StandardScaler())]),\n",
       "                                  Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "        'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "       dtype='object')),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(steps=[('imputer',\n",
       "                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                 strategy='constant')),\n",
       "                                                  ('oneHot',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                  Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "        'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "        'nursery', 'higher', 'internet', 'romantic'],\n",
       "       dtype='object'))]),\n",
       " 'pipeline-2__classifier': RandomForestClassifier(n_jobs=-1, random_state=1000),\n",
       " 'pipeline-2__preprocessor__n_jobs': None,\n",
       " 'pipeline-2__preprocessor__remainder': 'drop',\n",
       " 'pipeline-2__preprocessor__sparse_threshold': 0.3,\n",
       " 'pipeline-2__preprocessor__transformer_weights': None,\n",
       " 'pipeline-2__preprocessor__transformers': [('num',\n",
       "   Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                   ('scaler', StandardScaler())]),\n",
       "   Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "          'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2'],\n",
       "         dtype='object')),\n",
       "  ('cat',\n",
       "   Pipeline(steps=[('imputer',\n",
       "                    SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                   ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       "   Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "          'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "          'nursery', 'higher', 'internet', 'romantic'],\n",
       "         dtype='object'))],\n",
       " 'pipeline-2__preprocessor__verbose': False,\n",
       " 'pipeline-2__preprocessor__num': Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                 ('scaler', StandardScaler())]),\n",
       " 'pipeline-2__preprocessor__cat': Pipeline(steps=[('imputer',\n",
       "                  SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                 ('oneHot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'pipeline-2__preprocessor__num__memory': None,\n",
       " 'pipeline-2__preprocessor__num__steps': [('imputer',\n",
       "   SimpleImputer(strategy='median')),\n",
       "  ('scaler', StandardScaler())],\n",
       " 'pipeline-2__preprocessor__num__verbose': False,\n",
       " 'pipeline-2__preprocessor__num__imputer': SimpleImputer(strategy='median'),\n",
       " 'pipeline-2__preprocessor__num__scaler': StandardScaler(),\n",
       " 'pipeline-2__preprocessor__num__imputer__add_indicator': False,\n",
       " 'pipeline-2__preprocessor__num__imputer__copy': True,\n",
       " 'pipeline-2__preprocessor__num__imputer__fill_value': None,\n",
       " 'pipeline-2__preprocessor__num__imputer__missing_values': nan,\n",
       " 'pipeline-2__preprocessor__num__imputer__strategy': 'median',\n",
       " 'pipeline-2__preprocessor__num__imputer__verbose': 0,\n",
       " 'pipeline-2__preprocessor__num__scaler__copy': True,\n",
       " 'pipeline-2__preprocessor__num__scaler__with_mean': True,\n",
       " 'pipeline-2__preprocessor__num__scaler__with_std': True,\n",
       " 'pipeline-2__preprocessor__cat__memory': None,\n",
       " 'pipeline-2__preprocessor__cat__steps': [('imputer',\n",
       "   SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "  ('oneHot', OneHotEncoder(handle_unknown='ignore'))],\n",
       " 'pipeline-2__preprocessor__cat__verbose': False,\n",
       " 'pipeline-2__preprocessor__cat__imputer': SimpleImputer(fill_value='missing', strategy='constant'),\n",
       " 'pipeline-2__preprocessor__cat__oneHot': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'pipeline-2__preprocessor__cat__imputer__add_indicator': False,\n",
       " 'pipeline-2__preprocessor__cat__imputer__copy': True,\n",
       " 'pipeline-2__preprocessor__cat__imputer__fill_value': 'missing',\n",
       " 'pipeline-2__preprocessor__cat__imputer__missing_values': nan,\n",
       " 'pipeline-2__preprocessor__cat__imputer__strategy': 'constant',\n",
       " 'pipeline-2__preprocessor__cat__imputer__verbose': 0,\n",
       " 'pipeline-2__preprocessor__cat__oneHot__categories': 'auto',\n",
       " 'pipeline-2__preprocessor__cat__oneHot__drop': None,\n",
       " 'pipeline-2__preprocessor__cat__oneHot__dtype': numpy.float64,\n",
       " 'pipeline-2__preprocessor__cat__oneHot__handle_unknown': 'ignore',\n",
       " 'pipeline-2__preprocessor__cat__oneHot__sparse': True,\n",
       " 'pipeline-2__classifier__bootstrap': True,\n",
       " 'pipeline-2__classifier__ccp_alpha': 0.0,\n",
       " 'pipeline-2__classifier__class_weight': None,\n",
       " 'pipeline-2__classifier__criterion': 'gini',\n",
       " 'pipeline-2__classifier__max_depth': None,\n",
       " 'pipeline-2__classifier__max_features': 'auto',\n",
       " 'pipeline-2__classifier__max_leaf_nodes': None,\n",
       " 'pipeline-2__classifier__max_samples': None,\n",
       " 'pipeline-2__classifier__min_impurity_decrease': 0.0,\n",
       " 'pipeline-2__classifier__min_impurity_split': None,\n",
       " 'pipeline-2__classifier__min_samples_leaf': 1,\n",
       " 'pipeline-2__classifier__min_samples_split': 2,\n",
       " 'pipeline-2__classifier__min_weight_fraction_leaf': 0.0,\n",
       " 'pipeline-2__classifier__n_estimators': 100,\n",
       " 'pipeline-2__classifier__n_jobs': -1,\n",
       " 'pipeline-2__classifier__oob_score': False,\n",
       " 'pipeline-2__classifier__random_state': 1000,\n",
       " 'pipeline-2__classifier__verbose': 0,\n",
       " 'pipeline-2__classifier__warm_start': False}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
